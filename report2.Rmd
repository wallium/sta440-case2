---
title: "STA 440 Case 2"
author: "Annie Lott, Wuming Zhang, William Yang"
date: "October 18, 2017"
output: pdf_document
---

```{r setup,echo = FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(survival)
```

# Goals and Data Description

Getting treatment quickly after a stroke is crucial to a positive long-term prognosis. For emergency room patients who may have had a stroke, we are exploring the variables that influence the time it takes for these patients to receive a neurological assessment. The time from getting to the emergency room to receiving a neurological assessment, such as a CT scan, factors into the total time it takes for the patient to get treated for a stroke. This has a direct impact on the stroke patient's subsequent neurological health and survival.

Based on data from 335 emergency room patients with mild to moderate motor impairment, possibly indicative of a stroke, we are analyzing whether sex, race, ethnicity, and the number of symptoms displayed affects the time until the patients receive a neurological assessment, or whether or not they receive a neurological assessment at all. Sex is given as a binary variable of whether the patient is male (1) or female (0), race is a binary variable of whether the patient is black (1) or not (0), ethnicity is a binary variable of whether the patient is hispanic (1) or not (0), and the number of symtoms ranges from zero to four, with binary variables for if the patient exhibited one, two, three, or four symptoms (1 for each number of symptoms if they did exhibit this number, 0 for each number if they didn't). The four possible symptoms include a headache, loss of motor skills or weakness, trouble talking or understanding, and vision problems. Thus, given these variables, our goal is to build a model that predicts the amount of time until neurological assessment for potential stroke patients based on clinical presentation (how many symptoms the patient seems to have), gender and race and ethnicity, and to perform inference on the impact of these variables based on the model.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
data <- read.table("kellydat.txt", header = TRUE)

require(gridExtra)

kellydat = read.table("kellydat.txt", header = TRUE)
kellydat$sn0 = ifelse(kellydat$sn1 + kellydat$sn2 + kellydat$sn3 + kellydat$all4, 0, 1)
```

# Data Cleaning

For ease of analysis, we cleaned the data by introducing a numerical variable for the number of symptoms for each patient- zero, one, two, three, or four- rather than using binary variables for whether a particular number of symptoms were displayed or not. There were no missing data to recode for our analysis.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
kellydat$symptom = rep(0, length(kellydat$sn1))
for (i in 1:length(kellydat$nctdel)){
  if (kellydat$sn1[i] == 1){
    kellydat$symptom[i] = 1
  }
  if (kellydat$sn2[i] == 1){
    kellydat$symptom[i] = 2
  } 
  if (kellydat$sn3[i] == 1){
    kellydat$symptom[i] = 3
  }
  if (kellydat$all4[i] == 1){
    kellydat$symptom[i] = 4
  }
}
```

# Exploratory Data Analysis


## Histograms of each Indicator

```{r, echo=FALSE, warning=FALSE, message=FALSE}
all = ggplot(data=kellydat, aes(nctdel)) + geom_histogram() + ggtitle("all patients")
fail_1 = ggplot(data=kellydat[kellydat$fail == 1,], aes(nctdel)) + geom_histogram() + ggtitle("fail = 1")
fail_0 = ggplot(data=kellydat[kellydat$fail == 0,], aes(nctdel)) + geom_histogram() + ggtitle("fail = 0")
male_1 = ggplot(data=kellydat[kellydat$male == 1,], aes(nctdel)) + geom_histogram() + ggtitle("male = 1")
male_0 = ggplot(data=kellydat[kellydat$male == 0,], aes(nctdel)) + geom_histogram() + ggtitle("male = 0")
hisp_1 = ggplot(data=kellydat[kellydat$hisp == 1,], aes(nctdel)) + geom_histogram() + ggtitle("hisp = 1")
hisp_0 = ggplot(data=kellydat[kellydat$hisp == 0,], aes(nctdel)) + geom_histogram() + ggtitle("hisp = 0")
sn0_1 = ggplot(data=kellydat[kellydat$sn0 == 1,], aes(nctdel)) + geom_histogram() + ggtitle("0 symptoms")
sn1_1 = ggplot(data=kellydat[kellydat$sn1 == 1,], aes(nctdel)) + geom_histogram() + ggtitle("1 symptom")
sn2_1 = ggplot(data=kellydat[kellydat$sn2 == 1,], aes(nctdel)) + geom_histogram() + ggtitle("2 symptoms")
sn3_1 = ggplot(data=kellydat[kellydat$sn3 == 1,], aes(nctdel)) + geom_histogram() + ggtitle("3 symptoms")
all4_1 = ggplot(data=kellydat[kellydat$all4 == 1,], aes(nctdel)) + geom_histogram() + ggtitle("4 symptoms")

grid.arrange(all, fail_1, fail_0, male_1, male_0, hisp_1, hisp_0, sn0_1, sn1_1, sn2_1, sn3_1, all4_1, ncol=3)

```

To get a better sense of the distributions in the data, we first plot histograms of the nctdel times for each level of all the variables. We notice some general trends here - nctdel time seems to go down with more symptoms, the overall distribution of times for all patients is right-skewed with a mean around 1.5. However, we note that there are only 9 data points for hispanic patients, and only 6 for patients with all 4 symptoms. Inference around these variables will therefore have high variance.


# Kaplan-Meier Analysis
```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(survival)
par(mfrow=c(2,2))
d2 = Surv(time=kellydat$nctdel, event=kellydat$fail)

km1 = survfit(d2 ~ kellydat$male)
par(mar=c(4.5, 4.5, 0.5, 0.5))
plot(km1, col = c("red", "blue"), xlab = "time", ylab = "prob of survival (%)")
legend(15, 1.0, c("male", "female"), lty=c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))

km2 = survfit(d2 ~ kellydat$black)
plot(km2, col = c("red", "blue"), xlab = "time", ylab = "prob of survival (%)")
legend(13, 1.0, c("black", "not black"), lty=c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))

km3 = survfit(d2 ~ kellydat$hisp)
par(mar=c(4.5, 4.5, 0.5, 0.5))
plot(km3, col = c("red", "blue"), xlab = "time", ylab = "prob of survival (%)")
legend(11, 1.0, c("hispanic", "not hispanic"), lty=c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))

km4 = survfit(d2 ~ kellydat$symptom)
plot(km4, col = c("red", "blue", "green", "yellow", "black"), xlab = "time", ylab = "prob of survival (%)")
legend(11, 1.0, c("no symptom", "1 symptom", "2 symptoms", "3 symptoms", "4 symptoms"), lty=c(1,1), lwd=c(2.5,2.5),col=c("red", "blue", "green", "yellow", "black"))
```

Note that in our case, survival means that the patient still keeps waiting. The survival curves for males versus females look almost the same, suggesting that there is no significant difference in their chance of waiting at varied time. The survival curves for black patients versus non-black patients look a little different, with the probability of still waiting dropping off slightly more quickly for non-black patients as waiting time increases, but the difference is not substantial. There is a big difference between the survival curves for hispanic patients versus non-hispanic patients, but this difference may arise because there is so little data on hispanic patients. There seems to be large differences in the curves for the number of symptoms displayed, with most people having four symptoms being seen before about 2 time units, while people with no symptoms had a much less dramatic drop-off in the probability of still waiting, meaning that they were generally seen later. 


# Modeling Approaches

## Cox Proportional Hazards Model

One modeling approach we can take is fitting a Cox proportional hazards model for survival time to the dataset. We can use this to measure the effect that each level of the predictor variables has on the time to neurological assessment. 

```{r, echo=FALSE}
d3 = Surv(kellydat$nctdel, kellydat$fail)
cox = coxph(formula = d3 ~ black + male + hisp + symptom, data = kellydat)
summary(cox)
```

An initial implementation of the model on all the predictors does not identify any of them as having a significant effect. We will use other modeling approaches, generalized linear modeling with and without kernel regression, to verify if indeed the variables of clinical presentation, race, ethnicity, and gender have no impact on the time until clinical assessment for patients in the ER who are displaying symptoms potentially indicative of a stroke.

## Generalized Linear Modeling without Kernel Regression

Generalized linear modeling is a form of inference that abstracts linear regression so that the error distribution of the response variable does not have to be normal. In a generalized linear model, the linear predictor for the explanatory variables is related to the expected value of the response variable through the link function, which in this case is the log odds. We use the log odds as the link function because we are implementing logistic regression through the generalized linear model paradigm. The only relevant assumption made for our generalized linear model is the the wait times for patients are independent of each other, which we are comfortable making. We do not need to assume that the residuals are normally distributed or that they have equal variance. 

To implement generalized linear modeling, we needed to transform the data into a discrete format suitable for applying this technique, while taking into account censoring. We divided the times into uneven bins, with the first six bins of width 0.5, the seventh and eighth bins of width 1, and the rest of the bins of width 5. We did this because most of the wait times are low, but the wait time distribution is also right skewed. We used a data transformation method suitable for generalized linear modeling that centered around classifying each wait time into one of these bins.
```{r, echo = FALSE, warning = FALSE, message = FALSE}
# GLM without kernel
data_pp <- read.table("processed.csv", header=TRUE)
m1 = glm(assessment ~ p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 + p10 + p11 + p12 + p13 + male + black + hisp + sn1 + sn2 + sn3 + all4, data = data_pp)
summary(m1)
```

Based on the summary of the generalized linear model without kernel regression, only one explanatory variable coefficient is significant, the binary variable of whether the patient has all four stroke symptoms or not. The rest of the explanatory variables do not have statistically significant effects on the wait time. 

## Generalized Linear Modeling with Kernel Regression

To set up our generalized linear model with kernel regression, we first needed to transform the data in a similar fashion to the data conversion for our generalized linear modeling without kernel regression, but this time using bins of equal width for the wait times. We used seven kernels for the regression, and weighted the kernels for the lower bins (corresponding to the shorter wait times) more than the higher bins (corresponding to the longer wait times), because more patients had shorter wait times until clinical assessment. Again, we assume that the response variables for the patients are independent, and we don't need to check for normality or homoscedacity of the residuals for this model.

```{r, echo= FALSE, warning = FALSE, message = FALSE}
d = kellydat
times <- kellydat$nctdel
total_bins <- 26
bin_len <- max(times)/total_bins

censored <- kellydat$fail

# this is pretty ugly. Let's smooth it out with kernel regression.

# set up the kernels
kernels <- 7
#tau <- seq(from=1, to=total_bins, length.out = kernels)
tau = c(.2, .5, 1, 4, 9, 16, 25)
#sig = (tau[2]-tau[1])/2
#sigma <- c(sig,sig,sig,sig)
sigma = c(.15, .25, 1.5, 2.5, 3.5, 4.5, 6)

# we're going to pre-calculate a bunch of kernel weights
# each row is one bin, the columns are the kernel weights for that bin
kernel.weights <- matrix(dnorm(rep(1:total_bins,kernels),rep(tau,each=total_bins),rep(sigma,each=total_bins)), ncol=kernels)

# now we'll create a new transform function
kernel.transformation <- function(time, censored, total_bins, preds) {
  row_num <- ceiling(time/bin_len)
  if (time == 0){
    row_num = 1
  }
  y <- rep(0,row_num)
  if(censored) {
    y[row_num] <- 1
  }
  
  # X has kernel weights instead of the bin indicators that it had before
  X <- array(kernel.weights[1:row_num,],dim=c(row_num,kernels))
  
  vars = matrix(rep(c(preds[1,]$male,preds[1,]$black,preds[1,]$hisp,preds[1,]$sn1,preds[1,]$sn2,preds[1,]$sn3,preds[1,]$all4),row_num),
               row_num,7,byrow=TRUE)
  colnames(vars) = c("male", "black", "hisp", "sn1", "sn2", "sn3", "all4")

  return(data.frame(y,X,vars))
}

d2 <- kernel.transformation(times[1], censored[1], total_bins, d[1,])
rbind(d2, kernel.transformation(times[2], censored[2], total_bins, d[2,]))
for(i in 2:length(times)) {
  d2 <- rbind(d2, kernel.transformation(times[i], censored[i], total_bins, d[i,]))
}

m2 <- glm(y ~ 0 + ., data=d2, family="binomial")
summary(m2)
```
Based on the summary of the generalized linear model with kernel regression, none of the coefficients for the explanatory variables of race, ethnicity, gender, or number of symptoms are significant, contrasting with the results for the generalized linear model without kernel regression. 

# Conclusions

After an analysis of our Cox proportional hazard model, our generalized linear model created without kernel regression, and our generalized linear model generated with linear regression, we see that none of the predictors had any statistically significant correlation with the wait time until clinical assessment for a stroke, with a single exception. The predictors for wait time included whether or not the patient was black, whether or not the patient was Hispanic, whether the patient was male or female, and whether the patient displayed one, two, three, or four symptoms of a stroke. The only predictor with a statistically significant coefficient at an alpha of 0.05 was the variable for whether or not the patient displayed all four symptoms of a stroke, and this was only significant for the generalized linear model without kernel regression. The other models did not show statistical significance for the correlation of this explanatory variable with the wait time. We therefore conclude that none of the predictors in this study have an impact on the wait time until clinical assessment for a stroke, except for clinical presentation, which may have some effect when the patient displays all four symptoms of a stroke.

Although our models indicated that most of this study's explanatory variables were not significantly associated with wait time, this outcome may be a result of having too little data. For example, there were only nine Hispanic patients in this data set. If there had been more Hispanic patients, perhaps our models would have shown a statistically significant difference between the wait times of Hispanic and non-Hispanic patients. The problem of having too few observations affects the reliability of our results, but the only solution is to gather more data.

Even though our models show that most explanatory variables have no statistically significant impact on wait times, this result has positive implications even though it may initially seem uninteresting. Based on our analysis, the predictors of race, ethnicity, and gender have no impact on wait times, indicating that the selection process for clinical assessment in the ER is non-discriminatory. The only factor that may be relevant in influencing wait time is whether or not the patient has all four symptoms of a stroke. We would expect and hope that a patient with more stroke symptoms would have to wait less time for a clinical assessment, because it is even more urgent that this patient see a doctor. We have found evidence that suggests that a patient with stroke symptoms need not worry about discrimination in the emergency room based on race, ethinicity, or gender, and the only variable that may impact wait time is the number of symptoms exhibited.

# Goals for Further Analysis

In our next report, we hope to visualize the hazard curves for our models to better understand the process of waiting for a clinical assessment for a stroke. We also need to analyze different variations of each model to find the best fit. It may be that if we were to choose different kernel weights for our generalized linear model with kernel regression, the predictor of having all four symptoms of a stroke may show a statistically significant association with wait times in the ER. 

# References
“ Introduction to Generalized Linear Models.” \it{STAT 504}, Eberly College of Science at Penn State, onlinecourses.science.psu.edu/stat504/node/216.  



# Contributions
William and Wuming both helped transform the data for implementing the generalized linear model and the generalized linear model with kernel regression. Wuming and William wrote the code to use generalized linear models with and without kernel regression as well. Annie wrote the text for the conclusion and model approaches as well as added model analysis.  